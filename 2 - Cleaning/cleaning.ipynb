{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import regex as re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SQL Connection\n",
    "conn = sqlite3.connect('../data/GuidePod.sqlite')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all table names from GuidePod4 file\n",
    "tables_df = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "tables_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podcast_master\n",
    "podcasts_df = pd.read_sql_query(\"SELECT * FROM podcast_master\", conn)\n",
    "\n",
    "# podcast_reviews\n",
    "reviews_df = pd.read_sql_query(\"SELECT * FROM podcast_reviews\", conn)\n",
    "\n",
    "# episode_counts\n",
    "episodes_df = pd.read_sql_query(\"SELECT * FROM episode_counts\", conn)\n",
    "\n",
    "# genre_master\n",
    "genres_df = pd.read_sql_query(\"SELECT * FROM genre_master\", conn)\n",
    "\n",
    "# podcast_desc\n",
    "descriptions_df = pd.read_sql_query(\"SELECT * FROM podcast_desc\", conn)\n",
    "\n",
    "# episode_details\n",
    "episode_details_df = pd.read_sql_query(\"SELECT * FROM episode_details\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podcast Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates from COUNT(*) and COUNT(unique podcast IDs)\n",
    "cur.execute(\"\"\"\n",
    "SELECT\n",
    "  COUNT(*)\n",
    ", COUNT(DISTINCT id)\n",
    "FROM podcast_master \n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new dataframe to get clean data from podcasts_master (still duplicating 3 podcasts)\n",
    "\n",
    "podcasts_clean = pd.read_sql_query(\"\"\"\n",
    "WITH rank as \n",
    "(\n",
    "    SELECT \n",
    "      *\n",
    "    , ROW_NUMBER() OVER (PARTITION BY name, id) as ranked\n",
    "    FROM podcast_master \n",
    "    WHERE country = 'us'\n",
    "    GROUP BY 1,2,3,4,5,6,7,8\n",
    ")\n",
    "SELECT\n",
    "*\n",
    "FROM rank\n",
    "WHERE ranked = 1\n",
    "\"\"\", conn)\n",
    "\n",
    "podcasts_clean = podcasts_clean.drop(columns=['ranked'])\n",
    "podcasts_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use `podcasts_df` as the base dataset with all info in table\n",
    "\n",
    "> Use `podcasts_clean` dataset for modeling/analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episode Counts Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out Row 417\n",
    "episodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removed the row that contained header value\n",
    "episodes_df = episodes_df[episodes_df.name != 'name']\n",
    "episodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One duplicate name, make sure to join on ID \n",
    "episodes_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confirming they are different episodes with different IDs\n",
    "episodes_df[episodes_df.name == 'Motley Fool Money']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `episodes_df` is clean to use for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre Master Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Shows has two rows in here for whatever reason\n",
    "genres_df.groupby('genre').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Removing duplicates and getting unique values only\n",
    "genres_df = genres_df.drop_duplicates()\n",
    "genres_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `genres_df` is clean to use for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episode Details Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to clean out the duration so we get only the numbers instead of the string field\n",
    "\n",
    "episode_details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cleaning up the bad data\n",
    "# Create new field that contains itunes or is null, and extracting the numerical duration from string\n",
    "\n",
    "bad_durations = episode_details_df[episode_details_df['duration'].str.contains(\"itunes\") | episode_details_df['duration'].isnull()]\n",
    "bad_durations['new_duration'] = bad_durations['duration'].copy()\n",
    "bad_durations['new_duration'] = bad_durations['new_duration'].str.extract('(\\d+)')\n",
    "bad_durations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Updating episode_details_df with new_duration\n",
    "episode_details_df['new_duration'] = episode_details_df['duration']\n",
    "episode_details_df.update(bad_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some values in the bad_durations did not populate because they had no values\n",
    "# Turning those values into numbers and imputing them with averages\n",
    "# Taking one outlier and imputing with the average\n",
    "# Averages were calculated in Excel = 20,200\n",
    "\n",
    "avg_duration = 20200\n",
    "episode_details_df.loc[episode_details_df['new_duration'].str.contains('duration', na=False), 'new_duration'] = avg_duration\n",
    "episode_details_df.loc[episode_details_df['new_duration'] == 4294967295] = avg_duration\n",
    "episode_details_df.loc[episode_details_df['new_duration'].isna()] = avg_duration\n",
    "episode_details_df['new_duration'] = pd.to_numeric(episode_details_df['new_duration'])\n",
    "episode_details_df.loc[episode_details_df['new_duration'] < 100] = avg_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_details_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "episode_details_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_details_df.sort_values(by=['new_duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `episode_details_df` has a `new_duration` column that has the length of duration standardized in ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaving the episode description, reviews, and reviews for Gary & Harjot's word parsing and \n",
    "# cleaning libraries to clean up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_reviews = reviews_df[reviews_df['id'].isin(podcasts_clean['id']) & reviews_df['review_text'].notnull() & reviews_df['review_title'].notnull()]\n",
    "us_reviews = us_reviews[['id','review_title','review_text']]\n",
    "us_reviews['title'] = us_reviews.groupby(['id'], as_index=False)['review_title'].transform(lambda x : ' '.join(x))\n",
    "us_reviews['text'] = us_reviews.groupby(['id'], as_index=False)['review_text'].transform(lambda x : ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_reviews = us_reviews[['id','title','text']].drop_duplicates()\n",
    "reviews_clean = us_reviews.merge(descriptions_df, left_on = 'id', right_on='podcast_id', how='left')\n",
    "reviews_clean = reviews_clean[['id','title','text','description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['title', 'text', 'description']\n",
    "reviews_clean['combined'] = reviews_clean[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "reviews_clean = reviews_clean[['id','combined']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_score = reviews_df[['id','review_rating']].groupby('id').agg(['count','mean']).reset_index()\n",
    "reviews_score.columns = ['id','num_reviews','avg_review_score']\n",
    "reviews_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_final = reviews_clean.merge(reviews_score, on = 'id', how = 'left')\n",
    "reviews_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onlyWords(s):\n",
    "    return re.sub(r'[^\\w\\s]', ' ', s).strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_final.loc[:, 'combined'] = reviews_final.loc[:, 'combined'].apply(lambda x: onlyWords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episode Count Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get episode counts \n",
    "episode_counts = episode_details_df[['podcast_id','title']].groupby('podcast_id').count().reset_index()\n",
    "episode_counts.columns = ['podcast_id','episode_count']\n",
    "episode_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcast_duration = episode_details_df[['podcast_id','new_duration']].groupby('podcast_id').sum().reset_index()\n",
    "podcast_duration.columns = ['podcast_id','total_duration']\n",
    "podcast_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_final = episode_counts.merge(podcast_duration, on = 'podcast_id')\n",
    "episodes_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use podcasts_df as main\n",
    "# JOIN episodes_df for number of episodes\n",
    "# JOIN descriptions_df for description\n",
    "\n",
    "\n",
    "podcasts_cols = podcasts_clean[['id','name','releaseDate','Primary_Genre','Artist']]\n",
    "#episodes_cols = episodes_df[['id','episode_count']]\n",
    "#final_df = podcasts_cols.merge(episodes_cols, on = 'id', how = 'left')\n",
    "final_df = podcasts_cols.merge(episodes_final, left_on = 'id', right_on = 'podcast_id', how = 'inner')\n",
    "final_df = final_df.merge(reviews_final, on = 'id')\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(final_df['Primary_Genre'])\n",
    "dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_df = pd.concat([final_df,dummy], axis = 1)\n",
    "model_df.drop('podcast_id', axis = 'columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = model_df.iloc[3,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///..data/podcast_clean.sqlite', echo=True)\n",
    "sqlite_connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_table = \"podcast_model_data\"\n",
    "model_df.to_sql(sqlite_table, sqlite_connection, if_exists='fail')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
