{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import xml.etree.ElementTree as et\n",
    "from urllib.request import urlopen\n",
    "import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"..\\data\\podcast_ID_list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcasts = pd.read_csv(filename, index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection\n",
    "con = sqlite3.connect('../data/GuidePod_clean.sqlite')\n",
    "\n",
    "# import\n",
    "feeds = pd.read_sql_query(\"SELECT feedurl from podcast_master;\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(feed_url, podcast_id):\n",
    "    \n",
    "    resp = requests.get(feed_url)\n",
    "    bs = BeautifulSoup(resp.content, features='xml')\n",
    "    \n",
    "    def cleanhtml(raw_html):\n",
    "        cleaner = re.compile('<.*?>')\n",
    "        clean_text = re.sub(cleaner, '', raw_html)\n",
    "        return clean_text\n",
    "    \n",
    "    def hhmmss_sec(time_str):\n",
    "        h, m, s = time_str.split(':')\n",
    "        return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "    \n",
    "    def mmss_sec(time_str):\n",
    "        m, s = time_str.split(':')\n",
    "        return int(m) * 60 + int(s)\n",
    "\n",
    "    items = bs.findAll('item')\n",
    "    \n",
    "    show_items = []\n",
    "    \n",
    "    for index, item in enumerate(items):\n",
    "        episode = {}\n",
    "        episode['podcast_id'] = podcast_id\n",
    "        episode['title'] = item.title.text if item.title is not None else None\n",
    "        episode['description'] = cleanhtml(item.description.text) if item.description is not None else None\n",
    "\n",
    "        try:\n",
    "            if \":\" in item.duration.text:\n",
    "                dur_time = item.duration.text\n",
    "                dur_list = item.duration.text.split(':')\n",
    "\n",
    "                if len(dur_list) == 3:\n",
    "                    episode['duration'] = hhmmss_sec(dur_time)\n",
    "\n",
    "                if len(dur_list) == 2:\n",
    "                    episode['duration'] = mmss_sec(dur_time)\n",
    "\n",
    "            else:\n",
    "                episode['duration'] = item.duration if item.duration is not None else None\n",
    "        except:\n",
    "            print(\"podcast_id = \",podcast_id, \" feed_url = \", feed_url, \" row number = \", index, \" Duration issue\")\n",
    "            pass\n",
    "        episode['pubDate'] = item.pubDate.text if item.pubDate is not None else None      \n",
    "        show_items.append(episode)\n",
    "    \n",
    "    df_cols = [\"podcast_id\", \"title\", \"description\", \"duration\", \"pubDate\"]\n",
    "    \n",
    "    df = pd.DataFrame(show_items, columns = df_cols)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_all_shows(feeds):\n",
    "    df_list = []\n",
    "\n",
    "    for index, rows in tqdm(feeds.iterrows()):\n",
    "        feed_url = rows[\"FeedURL\"]\n",
    "        podcast_id = rows[\"id\"]\n",
    "        \n",
    "        try:\n",
    "            df = get_details(feed_url, podcast_id)\n",
    "            df_list.append(df)\n",
    "        \n",
    "        except:\n",
    "            print(podcast_id, feed_url, \"URL Error\")\n",
    "            pass\n",
    "\n",
    "    final_output = pd.concat(df_list)\n",
    "    \n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concat_all_shows(feeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove brackets from duration\n",
    "final_results['duration'] = final_results['duration'].astype(str).map(lambda x: x.lstrip('[').rstrip(']'))\n",
    "final_results.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results['duration'] = final_results['duration'].astype(str).map(lambda x: x.lstrip('<itunes:duration>').rstrip('</itunes:duration>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil\n",
    "from dateutil.relativedelta import *\n",
    "from dateutil.easter import *\n",
    "from dateutil.rrule import *\n",
    "from dateutil.parser import *\n",
    "\n",
    "def clean_pubdate(pubdate):\n",
    "    try:\n",
    "        date = dateutil.parser.parse(pubdate)\n",
    "        date = str(date).split(\" \")\n",
    "        date = date[0]\n",
    "    except:\n",
    "        print('error', pubdate)\n",
    "        date = pubdate\n",
    "        pass\n",
    "\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results['cleanDate'] = final_results['pubDate'].map(lambda x: clean_pubdate(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.replace(',','', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results['title'] = final_results['title'].str.lower()\n",
    "final_results['description'] = final_results['description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.replace('\\n','', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.replace('\\r',' ', regex=True, inplace=True)\n",
    "final_results.replace('  ',' ', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove all links with http or https as well as any emails xx@xxx\n",
    "final_results.replace('http\\S+|www.\\S+|\\S*@\\S*\\s?', '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all hyphens that is not in between words or numbers\n",
    "# only for the column title and description, because our dates have hyphens\n",
    "final_results['title'] = final_results['title'].str.replace('-(?!\\w)|(?<!\\w)-',' ')\n",
    "final_results['description'] = final_results['description'].str.replace('-(?!\\w)|(?<!\\w)-',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all puncuations\n",
    "# only for the column title and description\n",
    "import string\n",
    "\n",
    "def remove_punc(x):\n",
    "    punc = '''!()[]{};:|\"\\, <>./?@#$%^&*_~â€¢'''\n",
    "    try:\n",
    "        for ele in x:\n",
    "            if ele in punc:\n",
    "                x = x.replace(ele, \" \")\n",
    "        cleaned = x\n",
    "    except:\n",
    "        cleaned = x\n",
    "    return cleaned\n",
    "\n",
    "def remove_punc2(x):\n",
    "    try:\n",
    "        cleaned = x.strip(string.punctuation)\n",
    "    except:\n",
    "        cleaned = x\n",
    "    return cleaned\n",
    "\n",
    "final_results['title'] = final_results['title'].map(lambda x: remove_punc(x))\n",
    "final_results['description'] = final_results['description'].map(lambda x: remove_punc(x))\n",
    "\n",
    "final_results['title'] = final_results['title'].map(lambda x: remove_punc2(x))\n",
    "final_results['description'] = final_results['description'].map(lambda x: remove_punc2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results['title'] = '\"' + final_results['title'] + '\"'\n",
    "final_results['description'] = '\"' + final_results['description'] + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eachepisode in final_results.itertuples():\n",
    "    podcastid  =eachepisode[1] \n",
    "    title = eachepisode[2] \n",
    "    desc = eachepisode[3]\n",
    "    dura = eachepisode[4]\n",
    "    cur.execute('''INSERT INTO episode_detail values (?,?,?,?)''',(podcastid, title, desc, dura ))\n",
    "\n",
    "cur.close()\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
